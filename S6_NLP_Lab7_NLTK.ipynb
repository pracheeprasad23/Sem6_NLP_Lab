{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Prachee Prasad, 381060\n",
        "\n",
        "Lab 7: Develop a text preprocessing and analysis application using NLTK for tokenization, POS tagging, and basic NLP tasks."
      ],
      "metadata": {
        "id": "CXeIEZkw2CU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3MYDB1z0ir9",
        "outputId": "f6972067-361d-4b63-bf1b-5a66bfe1e3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n"
          ]
        }
      ],
      "source": [
        "#Install NLTK library\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import required libraries and download resources\n",
        "import nltk\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzucnK2V1SoJ",
        "outputId": "9646cd69-aeaf-4270-c1df-db27c1659d32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define sample input text\n",
        "text = \"\"\"\n",
        "Natural Language Processing is a fascinating field of Artificial Intelligence.\n",
        "NLTK helps in tokenization, tagging, and text analysis.\n",
        "\"\"\"\n",
        "\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wctque321U8E",
        "outputId": "3e56ecb6-2430-42de-fdbf-14c59083caf4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Natural Language Processing is a fascinating field of Artificial Intelligence.\n",
            "NLTK helps in tokenization, tagging, and text analysis.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean text (lowercase and remove punctuation)\n",
        "clean_text = text.lower()\n",
        "clean_text = re.sub(r'[^a-z\\s]', '', clean_text)\n",
        "\n",
        "print(\"Cleaned Text:\\n\", clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQy3bnFE1YZa",
        "outputId": "6d85ce2c-030b-49ad-9301-5269e08980da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            " \n",
            "natural language processing is a fascinating field of artificial intelligence\n",
            "nltk helps in tokenization tagging and text analysis\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform tokenization\n",
        "nltk.download('punkt_tab') # Download missing resource\n",
        "tokens = word_tokenize(clean_text)\n",
        "\n",
        "print(\"Tokens:\\n\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXZ7B3gH1c7W",
        "outputId": "2dca1aa4-e7ca-469a-9a4a-e9777959a9e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens:\n",
            " ['natural', 'language', 'processing', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', 'nltk', 'helps', 'in', 'tokenization', 'tagging', 'and', 'text', 'analysis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "print(\"After Stopword Removal:\\n\", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3Wr4xt91fiD",
        "outputId": "4a763f71-085e-4e5b-8c7e-aaf1e808a1e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Stopword Removal:\n",
            " ['natural', 'language', 'processing', 'fascinating', 'field', 'artificial', 'intelligence', 'nltk', 'helps', 'tokenization', 'tagging', 'text', 'analysis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform POS tagging\n",
        "nltk.download('averaged_perceptron_tagger_eng') # Download missing resource for English POS tagging\n",
        "pos_tags = pos_tag(filtered_tokens)\n",
        "\n",
        "print(\"POS Tags:\\n\", pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWe7dvMC1h6W",
        "outputId": "3040135c-5d69-4b85-f955-766f28216d53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tags:\n",
            " [('natural', 'JJ'), ('language', 'NN'), ('processing', 'VBG'), ('fascinating', 'JJ'), ('field', 'NN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('nltk', 'NN'), ('helps', 'VBZ'), ('tokenization', 'NN'), ('tagging', 'VBG'), ('text', 'JJ'), ('analysis', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "\n",
        "print(\"Lemmatized Words:\\n\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_0iw83s11wl",
        "outputId": "76c1cbb8-134b-4f39-bc90-baa032937958"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words:\n",
            " ['natural', 'language', 'processing', 'fascinating', 'field', 'artificial', 'intelligence', 'nltk', 'help', 'tokenization', 'tagging', 'text', 'analysis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform basic word frequency analysis\n",
        "word_freq = Counter(lemmatized_words)\n",
        "\n",
        "print(\"Word Frequency:\\n\", word_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgWDD-aN18KE",
        "outputId": "4bb9df89-7e9c-4558-888b-2f41815c568d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Frequency:\n",
            " Counter({'natural': 1, 'language': 1, 'processing': 1, 'fascinating': 1, 'field': 1, 'artificial': 1, 'intelligence': 1, 'nltk': 1, 'help': 1, 'tokenization': 1, 'tagging': 1, 'text': 1, 'analysis': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RgP_Pg_b2Biy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}