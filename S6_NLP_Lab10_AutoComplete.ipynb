{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Prachee Prasad, 381060\n",
        "\n",
        "Lab 10: Write a better auto-complete algorithm using an N-gram model (similar models are used for translation, determining the author of a text, and speech recognition)"
      ],
      "metadata": {
        "id": "8YZvc_RgC9QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install NLTK\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYf2NxWEDNe6",
        "outputId": "cf2adc03-bf2e-4a58-b2f3-505fc5142d44"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import required libraries\n",
        "import nltk\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHWfjwRmD9I8",
        "outputId": "944ba4d0-2898-4f69-a54f-fa29c01eee5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define training corpus\n",
        "\n",
        "corpus = \"\"\"\n",
        "Natural language processing is a field of artificial intelligence.\n",
        "Natural language processing helps computers understand language.\n",
        "Machine learning is used in natural language processing.\n",
        "Artificial intelligence and machine learning are related fields.\n",
        "\"\"\"\n",
        "\n",
        "# Clean text\n",
        "corpus = corpus.lower()\n",
        "corpus = re.sub(r'[^a-z\\s]', '', corpus)\n",
        "nltk.download('punkt_tab')\n",
        "tokens = word_tokenize(corpus)\n",
        "\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRQGKzMzD_hN",
        "outputId": "3e03e96e-cff6-4f49-ac1f-bd260f0ce787"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['natural', 'language', 'processing', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'natural', 'language', 'processing', 'helps', 'computers', 'understand', 'language', 'machine', 'learning', 'is', 'used', 'in', 'natural', 'language', 'processing', 'artificial', 'intelligence', 'and', 'machine', 'learning', 'are', 'related', 'fields']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Trigram Model\n",
        "\n",
        "n = 3  # Trigram\n",
        "ngrams = []\n",
        "\n",
        "for i in range(len(tokens) - n + 1):\n",
        "    ngrams.append(tuple(tokens[i:i+n]))\n",
        "\n",
        "# Create dictionary: (w1, w2) -> next word counts\n",
        "model = defaultdict(Counter)\n",
        "\n",
        "for w1, w2, w3 in ngrams:\n",
        "    model[(w1, w2)][w3] += 1\n",
        "\n",
        "print(\"Trigram model created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJFY-bl9EB7p",
        "outputId": "d9669ac6-7799-4af8-a961-ef5aa95739ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram model created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define auto-complete prediction function\n",
        "\n",
        "def predict_next_word(w1, w2):\n",
        "    w1, w2 = w1.lower(), w2.lower()\n",
        "\n",
        "    if (w1, w2) in model:\n",
        "        next_words = model[(w1, w2)]\n",
        "        prediction = next_words.most_common(1)[0][0]\n",
        "        return prediction\n",
        "    else:\n",
        "        return \"No prediction available\""
      ],
      "metadata": {
        "id": "rhdvdsn6EF7S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the auto-complete model\n",
        "\n",
        "print(\"Input: natural language\")\n",
        "print(\"Prediction:\", predict_next_word(\"natural\", \"language\"))\n",
        "\n",
        "print(\"\\nInput: machine learning\")\n",
        "print(\"Prediction:\", predict_next_word(\"machine\", \"learning\"))\n",
        "\n",
        "print(\"\\nInput: artificial intelligence\")\n",
        "print(\"Prediction:\", predict_next_word(\"artificial\", \"intelligence\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kjtkpNHEIKE",
        "outputId": "396b601d-d4b6-4b46-daae-1fa99d041c98"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: natural language\n",
            "Prediction: processing\n",
            "\n",
            "Input: machine learning\n",
            "Prediction: is\n",
            "\n",
            "Input: artificial intelligence\n",
            "Prediction: natural\n"
          ]
        }
      ]
    }
  ]
}